# Задача: обработать поток новостей, обнаружив в нём новости на определенную тематику.

### В рамках задачи были опробованы несколько подходов:
1. Бейзлайн в виде логистичсеской регрессии с tf-idf векторизацией
2. Zero-shot классфикация с ипользованием Huggingface и промта, выведенного по результатам бейзлайн подхода
3. Оптимизация моделей подбором гиперпараметров для LR и CatBoost c эмбеддингами, полученными из некоторых популярных чекпоинтов из Huggingface
4. Fine-tuning предобученной модели из Huggingface

Исследование данных проводилось в jupyter-ноутбуках **train_data_eda.ipynb**, **test_data_eda.ipynb**.

Fine-tuning проводился в **fine-tuning.ipynb**

В качестве метрики оценки работы моделей была выбрана метрика ROC-AUC. Она оценивает качество решений модели бинарной классификации в наиболее общем виде, учитывая все возможные пороговые значения.
Вместе с этим строились графики основных метрик в зависимости от разных порогов (Precision, Recall, F1, Accuracy), чтобы в совокупности оценить состоятельность результатов roc-auc.

По резульатам на отложенном тестовом (валидационном) наборе результаты получились следующими:
- LogisticRegression с TF-IDF (бейзлайн): **0.909** (получилось выделить признаки наиболее влияющие на работу модели - резульаты в файле **train_data_eda.ipynb**)
- zero-shot classification (cointegrated/rubert-base-cased-nli-threeway): **0.904**
- CatBoostClassifier c эмбедингами, полученными на основе чекпоинта ai-forever/sbert_large_nlu_ru: **0.912**
- LogisticRegression c эмбедингами, полученными на основе чекпоинта ai-forever/sbert_large_nlu_ru: **0.927**
- Fine-tuning ai-forever/sbert_large_nlu_ru: **0.892**

Подбор гиперпараметров осуществлялся с помощью **Optuna**

В качестве финальной модели была выбрана **LogisticRegression** с эмбеддингами на основе **ai-forever/sbert_large_nlu_ru**, показавшая лучшие результаты на тесте. 

Отобранные гиперпараметры модели сохранены в **best_params_lr.yaml**

Финальная модель хранится в файле **model_lr_proc.pkl**

Для того чтобы запустить обучение модели и формирование предсказаний, необоходимо настроить окружение:
```
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```
Запуск процесса обучения:
```
python3 fit_model.py
```

Получение предсказаний:
```
python3 make_prediction.py
```
Результат сохранится в файле **test_data.csv** с добавленным полем, содержащим вероятность принадлежности новости к положительному классу.

В процессе исследования файла test_data.csv было обнаружено, что некорректно считывается строка 1873. Это единичный случай, можно было исправить вручную, но обработка такого момента реализована в **make_prediction.py**
